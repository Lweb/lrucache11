/*
 * LRUCache11 - a templated C++11 based LRU cache class that allows
 * specification of key, value
 *
 * This is a header-only library and all you need is the LRUCache11.hpp file
 *
 * Github: https://github.com/mohaps/lrucache11
 *
 * This is a follow-up to the LRUCache project -
 * https://github.com/mohaps/lrucache
 *
 * Copyright (c) 2012-22 SAURAV MOHAPATRA <mohaps@gmail.com>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 */
#pragma once

#include <algorithm>
#include <cstdint>
#include <list>
#include <mutex>
#include <shared_mutex>
#include <unordered_map>

namespace lru11 {
  template<typename K, typename V>
  struct KeyValuePair {
    K key;
    V value;

    KeyValuePair(K k, V v) : key(std::move(k)), value(std::move(v)) {}
  };

/**
 * Cache is a thread-safe hashtable with a limited size. When it is full, insert()
 * evicts the least recently used item from the cache.
 * Cache uses a read write lock for the inner map and a write lock for the inner
 * list. The acquisition of the list lock during get() operation is non-blocking (try_lock),
 * so under heavy lookup load, the container will not stall, instead some LRU update operations
 * will be omitted.
 */
  template<class Key, class Value>
  class Cache {
  public:
    using node_type = KeyValuePair<Key, Value>;
    using map_type = std::unordered_map<Key, typename std::list<node_type>::iterator>;
    using list_type = std::list<node_type>;

    // disallow copying
    Cache(const Cache&) = delete;
    Cache& operator=(const Cache&) = delete;

    /**
     * @param maxSize maxSize = 0 means unbounded capacity
     */
    explicit Cache(size_t maxSize = 64) : maxSize_(maxSize) {}

    virtual ~Cache() = default;

    void clear() {
      std::lock_guard<std::shared_mutex> mapWriteLock(mapMtx_);
      std::lock_guard<std::mutex> listWriteLock(listMtx_);
      map_.clear();
      list_.clear();
    }

    /**
     * insert will store the copy of the key and value
     */
    void insert(const Key& key, const Value& value) {
      std::lock_guard<std::shared_mutex> mapWriteLock(mapMtx_);
      std::lock_guard<std::mutex> listWriteLock(listMtx_);
      const auto iter = map_.find(key);
      if (iter != map_.end()) {
        iter->second->value = value;
        list_.splice(list_.begin(), list_, iter->second);
        return;
      }

      list_.emplace_front(key, value);
      map_[key] = list_.begin();
      prune();
    }

    /**
     * @return a optional of the copy from the stored value (if found),
     * using Value = shared_ptr to achieve reference semantics
     */
    std::optional<Value> get(const Key& key) {
      std::shared_lock<std::shared_mutex> mapReadLock(mapMtx_);
      const auto iter = map_.find(key);
      if (iter == map_.end()) {
        return std::optional<Value> {};
      }
      tryPromote(iter->second);
      return std::make_optional<Value>(iter->second->value);
    }

    /**
     * if key is not in cache, insert this key to cache with the value
     * generated by the supplier
     */
    Value getWithSupplier(const Key& key, const std::function<Value()>& supplier) {
      std::lock_guard<std::shared_mutex> mapWriteLock(mapMtx_);
      std::lock_guard<std::mutex> listWriteLock(listMtx_);
      const auto iter = map_.find(key);
      if (iter != map_.end()) {
        list_.splice(list_.begin(), list_, iter->second);
        return iter->second->value;
      }

      Value value = supplier();
      list_.emplace_front(key, value);
      map_[key] = list_.begin();
      prune();
      return value;
    }

    size_t getMaxSize() const { return maxSize_; }

  protected:
    size_t prune() {
      if (maxSize_ == 0 || map_.size() < maxSize_) {
        return 0;
      }
      size_t count = 0;
      while (map_.size() > maxSize_) {
        map_.erase(list_.back().key);
        list_.pop_back();
        ++count;
      }
      return count;
    }

    void tryPromote(typename list_type::iterator iter) {
      std::unique_lock<std::mutex> listWriteLock(listMtx_, std::try_to_lock);
      if (listWriteLock) {
        list_.splice(list_.begin(), list_, iter);
      }
    }

  private:
    mutable std::shared_mutex mapMtx_;
    mutable std::mutex listMtx_;
    map_type map_;
    list_type list_;
    size_t maxSize_;
  };

}  // namespace LRUCache11
